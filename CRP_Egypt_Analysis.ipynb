{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/7w99lfvx0cl74dtmhv3y6gfc0000gn/T/ipykernel_36400/831142771.py:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/amaury/Documents/!DSBA/CRP/headlines_english_arabic_countries.csv')\n"
     ]
    }
   ],
   "source": [
    "# Data import\n",
    "#df=pd.read_csv('/Users/jeanlahellec/Library/Mobile Documents/com~apple~CloudDocs/Master ESSEC/headlines_english_arabic_countries.csv')\n",
    "df = pd.read_csv('/Users/amaury/Documents/!DSBA/CRP/headlines_english_arabic_countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gkgrecordid</th>\n",
       "      <th>date</th>\n",
       "      <th>subsourcecommonname</th>\n",
       "      <th>documentidentifier</th>\n",
       "      <th>enhancedthemes</th>\n",
       "      <th>enhancedlocations</th>\n",
       "      <th>tone</th>\n",
       "      <th>extrasxml</th>\n",
       "      <th>translationinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20151011213000-456</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>dailynewsegypt.com</td>\n",
       "      <td>http://www.dailynewsegypt.com/2015/10/11/tgm-m...</td>\n",
       "      <td>ECON_WORLDCURRENCIES_DOLLAR,2612;ECON_WORLDCUR...</td>\n",
       "      <td>4#Milan, Lombardia, Italy#IT#IT09#18363#45.466...</td>\n",
       "      <td>1.76991150442478,2.54424778761062,0.7743362831...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20151011213000-1551</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>gizmodo.com.au</td>\n",
       "      <td>http://www.gizmodo.com.au/2015/10/5-ideas-that...</td>\n",
       "      <td>MANMADE_DISASTER_IMPLIED,58;MANMADE_DISASTER_I...</td>\n",
       "      <td>3#Manhattan, New York, United States#US#USNY#N...</td>\n",
       "      <td>0.843320017754106,2.13049267643142,1.287172658...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20151011213000-1644</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>competitor.com</td>\n",
       "      <td>http://velonews.competitor.com/2015/10/news/ch...</td>\n",
       "      <td>WB_2670_JOBS,696;WB_2815_SKILLS_AND_EDUCATION,...</td>\n",
       "      <td>4#Abu Dhabi, Abu ZÂ¸Aby, United Arab Emirates#...</td>\n",
       "      <td>4.83271375464684,4.83271375464684,0,4.83271375...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20151016043000-1997</td>\n",
       "      <td>2.015102e+13</td>\n",
       "      <td>daily-chronicle.com</td>\n",
       "      <td>http://www.daily-chronicle.com/2015/10/15/saud...</td>\n",
       "      <td>GENERAL_GOVERNMENT,620;GENERAL_GOVERNMENT,4524...</td>\n",
       "      <td>4#Baghdad, Baghdad, Iraq#IZ#IZ07#36785#33.3386...</td>\n",
       "      <td>-4.35754189944134,1.11731843575419,5.474860335...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20151011150000-503</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>dailynewsegypt.com</td>\n",
       "      <td>http://www.dailynewsegypt.com/2015/10/11/sharp...</td>\n",
       "      <td>KIDNAP,2150;EXTREMISM,2184;BORDER,2772;TAX_REL...</td>\n",
       "      <td>4#Gaza, Israel (General), Israel#IS#IS00#18315...</td>\n",
       "      <td>-9.05730129390018,0.924214417744917,9.98151571...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gkgrecordid          date  subsourcecommonname  \\\n",
       "0   20151011213000-456  2.015101e+13   dailynewsegypt.com   \n",
       "1  20151011213000-1551  2.015101e+13       gizmodo.com.au   \n",
       "2  20151011213000-1644  2.015101e+13       competitor.com   \n",
       "3  20151016043000-1997  2.015102e+13  daily-chronicle.com   \n",
       "4   20151011150000-503  2.015101e+13   dailynewsegypt.com   \n",
       "\n",
       "                                  documentidentifier  \\\n",
       "0  http://www.dailynewsegypt.com/2015/10/11/tgm-m...   \n",
       "1  http://www.gizmodo.com.au/2015/10/5-ideas-that...   \n",
       "2  http://velonews.competitor.com/2015/10/news/ch...   \n",
       "3  http://www.daily-chronicle.com/2015/10/15/saud...   \n",
       "4  http://www.dailynewsegypt.com/2015/10/11/sharp...   \n",
       "\n",
       "                                      enhancedthemes  \\\n",
       "0  ECON_WORLDCURRENCIES_DOLLAR,2612;ECON_WORLDCUR...   \n",
       "1  MANMADE_DISASTER_IMPLIED,58;MANMADE_DISASTER_I...   \n",
       "2  WB_2670_JOBS,696;WB_2815_SKILLS_AND_EDUCATION,...   \n",
       "3  GENERAL_GOVERNMENT,620;GENERAL_GOVERNMENT,4524...   \n",
       "4  KIDNAP,2150;EXTREMISM,2184;BORDER,2772;TAX_REL...   \n",
       "\n",
       "                                   enhancedlocations  \\\n",
       "0  4#Milan, Lombardia, Italy#IT#IT09#18363#45.466...   \n",
       "1  3#Manhattan, New York, United States#US#USNY#N...   \n",
       "2  4#Abu Dhabi, Abu ZÂ¸Aby, United Arab Emirates#...   \n",
       "3  4#Baghdad, Baghdad, Iraq#IZ#IZ07#36785#33.3386...   \n",
       "4  4#Gaza, Israel (General), Israel#IS#IS00#18315...   \n",
       "\n",
       "                                                tone extrasxml  \\\n",
       "0  1.76991150442478,2.54424778761062,0.7743362831...       NaN   \n",
       "1  0.843320017754106,2.13049267643142,1.287172658...       NaN   \n",
       "2  4.83271375464684,4.83271375464684,0,4.83271375...       NaN   \n",
       "3  -4.35754189944134,1.11731843575419,5.474860335...       NaN   \n",
       "4  -9.05730129390018,0.924214417744917,9.98151571...       NaN   \n",
       "\n",
       "   translationinfo  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the tone column into a list\n",
    "def convert_into_list(string):\n",
    "    listos = list(string.split(\",\"))\n",
    "    listos = [eval(i) for i in listos] # to get a float list\n",
    "    return listos\n",
    "\n",
    "df.tone = df.tone.apply(lambda x: convert_into_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.76991150442478, 2.54424778761062, 0.774336283185841, 3.31858407079646, 18.9159292035398, 1.43805309734513, 849]\n",
      "4.3141592920354\n"
     ]
    }
   ],
   "source": [
    "# Checking the tone transformation\n",
    "print(df.tone[0])\n",
    "print(df.tone[0][0]+df.tone[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tone columns\n",
    "df['mean_tone'] = df.tone.apply(lambda x: x[0])\n",
    "df['pos_tone'] = df.tone.apply(lambda x: x[1])\n",
    "df['neg_tone'] = df.tone.apply(lambda x: x[2])\n",
    "df['binary_tone'] = df.tone.apply(lambda x: 1 if x[1] > x[2] else 0) # 1 if pos_tone > neg_tone otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: binary_tone, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.binary_tone.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20151011213000.0 <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# Check type date\n",
    "print(df.date.iloc[0],type(df.date.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2015-10-11 21:30:00\n",
       "1        2015-10-11 21:30:00\n",
       "2        2015-10-11 21:30:00\n",
       "3        2015-10-16 04:30:00\n",
       "4        2015-10-11 15:00:00\n",
       "                 ...        \n",
       "773841   2023-03-07 13:45:00\n",
       "773842   2023-03-07 19:15:00\n",
       "773843   2023-03-07 19:15:00\n",
       "773844   2023-03-07 19:15:00\n",
       "773845   2023-03-07 19:15:00\n",
       "Name: date, Length: 773846, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date conversion\n",
    "df.date = df.date.apply(lambda x: datetime.strptime(str(int(x)), '%Y%m%d%H%M%S'))\n",
    "df.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ECON_WORLDCURRENCIES_DOLLAR,2612;ECON_WORLDCURRENCIES_US_DOLLAR,2612;TAX_FNCACT_TENANTS,2567;TAX_FNCACT_TENANTS,2667;AFFECT,2532;NEGOTIATIONS,1137;NEGOTIATIONS,2805;NEGOTIATIONS,4173;WB_840_JUSTICE,1137;WB_840_JUSTICE,2805;WB_840_JUSTICE,4173;WB_2473_DIPLOMACY_AND_NEGOTIATIONS,1137;WB_2473_DIPLOMACY_AND_NEGOTIATIONS,2805;WB_2473_DIPLOMACY_AND_NEGOTIATIONS,4173;WB_939_NEGOTIATION,1137;WB_939_NEGOTIATION,2805;WB_939_NEGOTIATION,4173;WB_2470_PEACE_OPERATIONS_AND_CONFLICT_MANAGEMENT,1137;WB_2470_PEACE_OPERATIONS_AND_CONFLICT_MANAGEMENT,2805;WB_2470_PEACE_OPERATIONS_AND_CONFLICT_MANAGEMENT,4173;WB_936_ALTERNATIVE_DISPUTE_RESOLUTION,1137;WB_936_ALTERNATIVE_DISPUTE_RESOLUTION,2805;WB_936_ALTERNATIVE_DISPUTE_RESOLUTION,4173;WB_2432_FRAGILITY_CONFLICT_AND_VIOLENCE,1137;WB_2432_FRAGILITY_CONFLICT_AND_VIOLENCE,2805;WB_2432_FRAGILITY_CONFLICT_AND_VIOLENCE,4173;WB_843_DISPUTE_RESOLUTION,1137;WB_843_DISPUTE_RESOLUTION,2805;WB_843_DISPUTE_RESOLUTION,4173;WB_2471_PEACEKEEPING,1137;WB_2471_PEACEKEEPING,2805;WB_2471_PEACEKEEPING,4173;CRISISLEX_T11_UPDATESSYMPATHY,5033;ECON_HOUSING_PRICES,84;ECON_HOUSING_PRICES,1169;ECON_HOUSING_PRICES,3046;ECON_HOUSING_PRICES,3102;ECON_HOUSING_PRICES,3652;ECON_HOUSING_PRICES,4443;WB_678_DIGITAL_GOVERNMENT,4645;WB_694_BROADCAST_AND_MEDIA,4645;WB_133_INFORMATION_AND_COMMUNICATION_TECHNOLOGIES,4645;ECON_WORLDCURRENCIES_DOLLARS,2505;USPEC_POLICY1,5054;WB_368_LEASING,595;TAX_ECON_PRICE,2912;URBAN,1063;TAX_FNCACT_AGENT,677;TAX_FNCACT_AGENT,4691;TAX_ETHNICITY_ARAB,3287;TAX_FNCACT_WORKERS,1753;ECON_WORLDCURRENCIES_EGYPTIAN_POUNDS,2523;WB_845_LEGAL_AND_REGULATORY_FRAMEWORK,462;WB_845_LEGAL_AND_REGULATORY_FRAMEWORK,1970;WB_696_PUBLIC_SECTOR_MANAGEMENT,462;WB_696_PUBLIC_SECTOR_MANAGEMENT,1970;WB_851_INTELLECTUAL_PROPERTY_RIGHTS,462;WB_851_INTELLECTUAL_PROPERTY_RIGHTS,1970;WB_1042_TRADEMARKS,462;WB_1042_TRADEMARKS,1970;WB_1039_PROPERTY_LAWS_AND_REGULATIONS,462;WB_1039_PROPERTY_LAWS_AND_REGULATIONS,1970;'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check enhanced themes format\n",
    "df.enhancedthemes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cleaning of the headlines\n",
    "def headlines_cleaning(s_):\n",
    "    s_ = str(s_)\n",
    "    modified_str = [elem.split(',')[0] for elem in s_.split(';')] # delete the number after the coma\n",
    "\n",
    "    final_str=[]\n",
    "    separator=' '\n",
    "    for s in modified_str:\n",
    "        if s.split('_')[0]=='WB':\n",
    "            final_str.append(separator.join(s.split('_')[2:]).split(' ')) # delete the prefix 'WB_XXX', remove underscore and split each word\n",
    "        else:\n",
    "            final_str.append(separator.join(s.split('_')).split(' '))\n",
    "\n",
    "    # to get a list of words and not a list of sub lists\n",
    "    merged_list = []\n",
    "    for sublist in final_str:\n",
    "        merged_list.extend(sublist)\n",
    "\n",
    "    return(merged_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DISPUTE', 'RESOLUTION', 'DISPUTE', 'RESOLUTION', 'TEST', 'TESTOS'] DISPUTE\n"
     ]
    }
   ],
   "source": [
    "# Test of cleaning\n",
    "original_str = 'WB_843_DISPUTE_RESOLUTION,1137;WB_843_DISPUTE_RESOLUTION,2805;TEST_TESTOS,2021'\n",
    "res = headlines_cleaning(original_str)\n",
    "print(res, res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [ECON, WORLDCURRENCIES, DOLLAR, ECON, WORLDCUR...\n",
       "1         [MANMADE, DISASTER, IMPLIED, MANMADE, DISASTER...\n",
       "2         [JOBS, SKILLS, AND, EDUCATION, JOBS, STRATEGIE...\n",
       "3         [GENERAL, GOVERNMENT, GENERAL, GOVERNMENT, TAX...\n",
       "4         [KIDNAP, EXTREMISM, BORDER, TAX, RELIGION, MUS...\n",
       "                                ...                        \n",
       "773841    [GENERAL, GOVERNMENT, GENERAL, GOVERNMENT, EPU...\n",
       "773842    [GENERAL, HEALTH, MEDICAL, TAX, FNCACT, VICE, ...\n",
       "773843                                                [nan]\n",
       "773844    [GENERAL, GOVERNMENT, EPU, POLICY, GOVERNMENT,...\n",
       "773845    [PROTEST, EPU, CATS, NATIONAL, SECURITY, TAX, ...\n",
       "Name: enhancedthemes, Length: 773846, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.enhancedthemes.apply(lambda x: headlines_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gkgrecordid                 0\n",
      "date                        0\n",
      "subsourcecommonname       103\n",
      "documentidentifier          0\n",
      "enhancedthemes          80673\n",
      "enhancedlocations           0\n",
      "tone                        0\n",
      "extrasxml              221985\n",
      "translationinfo        773846\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking null values\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)\n",
    "# Drop empty headlines/sources\n",
    "df = df.dropna(subset=['enhancedthemes'])\n",
    "df = df.dropna(subset=['subsourcecommonname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the theme filter keywords \n",
    "def filtering_themes(dataframe,theme):\n",
    "\n",
    "    if theme == 'CONSUMPTION':\n",
    "        filter = ['CONSUMPTION','CONSUME','CONSUMER','PURCHASE','PURCHASING','PURCHASER','BUYER']\n",
    "        themes_filtered_df = dataframe[dataframe['enhancedthemes'].apply(lambda x: any(keyword in x for keyword in filter))]\n",
    "\n",
    "    elif theme == 'TRADE':\n",
    "        filter = ['TRADE','MARKET']\n",
    "        themes_filtered_df = dataframe[dataframe['enhancedthemes'].apply(lambda x: any(keyword in x for keyword in filter))]\n",
    "\n",
    "    elif theme == 'EMPLOYMENT':\n",
    "        filter = ['EMPLOYMENT','UNEMPLOYMENT']\n",
    "        themes_filtered_df = dataframe[dataframe['enhancedthemes'].apply(lambda x: any(keyword in x for keyword in filter))]\n",
    "    \n",
    "    else:\n",
    "        print('Theme is not recognised, please select between: \"CONSUMPTION\", \"TRADE\", \"EMPLOYMENT\".')\n",
    "\n",
    "    return(themes_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtering_themes(df,'CONSUMPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2015     626\n",
      "2016    1013\n",
      "2017     826\n",
      "2018     772\n",
      "2019     629\n",
      "2020     411\n",
      "2021     335\n",
      "2022     374\n",
      "2023      54\n",
      "Name: enhancedthemes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the filtered number of articles per year\n",
    "nb_articles= filtered_df.groupby(filtered_df.date.dt.year)['enhancedthemes'].count()\n",
    "print(nb_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: mean_tone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/amaury/Documents/!DSBA/CRP/CRP_Egyptian_Economy/CRP_Egypt_Analysis.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amaury/Documents/%21DSBA/CRP/CRP_Egyptian_Economy/CRP_Egypt_Analysis.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Average of the tone of articles per year\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amaury/Documents/%21DSBA/CRP/CRP_Egyptian_Economy/CRP_Egypt_Analysis.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m avg_tone \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39;49mgroupby(filtered_df\u001b[39m.\u001b[39;49mdate\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39;49myear)[\u001b[39m'\u001b[39;49m\u001b[39mmean_tone\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amaury/Documents/%21DSBA/CRP/CRP_Egyptian_Economy/CRP_Egypt_Analysis.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(avg_tone)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1338\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[39m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1335\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1336\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1337\u001b[0m     )\n\u001b[0;32m-> 1338\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py:250\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn not found: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key]\n\u001b[1;32m    252\u001b[0m     ndim \u001b[39m=\u001b[39m subset\u001b[39m.\u001b[39mndim\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: mean_tone'"
     ]
    }
   ],
   "source": [
    "# Average of the tone of articles per year\n",
    "avg_tone = filtered_df.groupby(filtered_df.date.dt.year)['mean_tone'].mean()\n",
    "print(avg_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def location_cleaning(s_):\n",
    "    s_ = str(s_)\n",
    "    modified_str = [elem.split('#') for elem in re.split(';|, ', s_)]  # delete the hastags and semicolomm, llist of lists\n",
    "    merged_list = [item for sublist in modified_str for item in sublist]  # merge sublists\n",
    "    final_list=[s for s in merged_list if s.isalpha()] # remove duplicates and non-alphanumeric elements\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Milan',\n",
       " 'Lombardia',\n",
       " 'Italy',\n",
       " 'IT',\n",
       " 'Cairo',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Cairo',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Alexandria',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Alexandria',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Paris',\n",
       " 'France',\n",
       " 'FR',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Dubai',\n",
       " 'Dubayy',\n",
       " 'AE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_cleaning(df.enhancedlocations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['enhancedlocations']=df.enhancedlocations.apply(lambda x: location_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Milan, Lombardia, Italy, IT, Cairo, Egypt, EG...\n",
       "1    [Manhattan, US, USNY, Manhattan, US, USNY, UK,...\n",
       "2                                                 [AE]\n",
       "3    [Baghdad, Baghdad, Iraq, IZ, Baghdad, Baghdad,...\n",
       "4    [Gaza, Israel, IS, Gaza, Israel, IS, Cairo, Eg...\n",
       "Name: enhancedlocations, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['enhancedlocations'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/m8tf5s7d4bz_k2fcgvs7r_wr0000gn/T/ipykernel_88667/2904860164.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['enhancedlocations']=df['enhancedlocations']\n"
     ]
    }
   ],
   "source": [
    "filtered_df['enhancedlocations']=df['enhancedlocations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Milan',\n",
       " 'Lombardia',\n",
       " 'Italy',\n",
       " 'IT',\n",
       " 'Cairo',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Cairo',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Alexandria',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Alexandria',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egypt',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Paris',\n",
       " 'France',\n",
       " 'FR',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Egyptian',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'EG',\n",
       " 'Dubai',\n",
       " 'Dubayy',\n",
       " 'AE']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['enhancedlocations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered_df[\u001b[39m'\u001b[39;49m\u001b[39menhancedlocations\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m2\u001b[39;49m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "filtered_df['enhancedlocations'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of the filter keywords \n",
    "#country_filter = ['Egypt','Cairo','Alexandria']\n",
    "theme_filter = ['Egypt','EG', 'Cairo', 'Alexandria', 'Egyptian']\n",
    "\n",
    "def filtered(liste, filter):\n",
    "    filtered_words=[elem for elem in liste if elem in theme_filter ]\n",
    "    ratio= len(filtered_words)/len(liste)\n",
    "    return(ratio)\n",
    "# Filtering by theme\n",
    "\n",
    "filtered(df['enhancedlocations'][8], theme_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/m8tf5s7d4bz_k2fcgvs7r_wr0000gn/T/ipykernel_88667/1781459543.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['enhanced_ratio'] = filtered_df.enhancedlocations.apply(lambda x: filtered(x, theme_filter))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gkgrecordid</th>\n",
       "      <th>date</th>\n",
       "      <th>subsourcecommonname</th>\n",
       "      <th>documentidentifier</th>\n",
       "      <th>enhancedthemes</th>\n",
       "      <th>enhancedlocations</th>\n",
       "      <th>tone</th>\n",
       "      <th>extrasxml</th>\n",
       "      <th>translationinfo</th>\n",
       "      <th>mean_tone</th>\n",
       "      <th>enhanced_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20151011213000-456</td>\n",
       "      <td>2015-10-11 21:30:00</td>\n",
       "      <td>dailynewsegypt.com</td>\n",
       "      <td>http://www.dailynewsegypt.com/2015/10/11/tgm-m...</td>\n",
       "      <td>ECON_WORLDCURRENCIES_DOLLAR,2612;ECON_WORLDCUR...</td>\n",
       "      <td>[Milan, Lombardia, Italy, IT, Cairo, Egypt, EG...</td>\n",
       "      <td>[1.76991150442478, 2.54424778761062, 0.7743362...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.793510</td>\n",
       "      <td>0.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20151011150000-539</td>\n",
       "      <td>2015-10-11 15:00:00</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>https://en-maktoob.news.yahoo.com/mideast-stoc...</td>\n",
       "      <td>ECON_OILPRICE,114;ECON_STOCKMARKET,52;ECON_STO...</td>\n",
       "      <td>[Dubayy, AE, Qatar, QA, QA, QA, Qatar, QA, QA,...</td>\n",
       "      <td>[0.465116279069767, 0.930232558139535, 0.46511...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.720930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20151017084500-1217</td>\n",
       "      <td>2015-10-17 08:45:00</td>\n",
       "      <td>barossaherald.com.au</td>\n",
       "      <td>http://www.barossaherald.com.au/story/3429242/...</td>\n",
       "      <td>TAX_FNCACT_BACKBENCHER,2073;AGRICULTURE,907;AG...</td>\n",
       "      <td>[Indonesian, ID, ID, ID, Australian, AS, AS, A...</td>\n",
       "      <td>[-4.93506493506493, 2.07792207792208, 7.012987...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.238095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20151017104500-1406</td>\n",
       "      <td>2015-10-17 10:45:00</td>\n",
       "      <td>cachevalleydaily.com</td>\n",
       "      <td>http://www.cachevalleydaily.com/news/national/...</td>\n",
       "      <td>TAX_FNCACT_CANDIDATES,163;TAX_FNCACT_CANDIDATE...</td>\n",
       "      <td>[Alexandria, Egypt, EG, Alexandria, Egypt, EG,...</td>\n",
       "      <td>[0.453857791225415, 5.29500756429652, 4.841149...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.707010</td>\n",
       "      <td>0.995745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20151018111500-724</td>\n",
       "      <td>2015-10-18 11:15:00</td>\n",
       "      <td>dubaicityguide.com</td>\n",
       "      <td>http://www.dubaicityguide.com/site/news/news-d...</td>\n",
       "      <td>SOC_EMERGINGTECH,1781;WB_1467_EDUCATION_FOR_AL...</td>\n",
       "      <td>[Dubai, Dubayy, AE]</td>\n",
       "      <td>[3.93873085339168, 4.37636761487965, 0.4376367...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.856309</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gkgrecordid                date   subsourcecommonname  \\\n",
       "0    20151011213000-456 2015-10-11 21:30:00    dailynewsegypt.com   \n",
       "5    20151011150000-539 2015-10-11 15:00:00             yahoo.com   \n",
       "8   20151017084500-1217 2015-10-17 08:45:00  barossaherald.com.au   \n",
       "15  20151017104500-1406 2015-10-17 10:45:00  cachevalleydaily.com   \n",
       "31   20151018111500-724 2015-10-18 11:15:00    dubaicityguide.com   \n",
       "\n",
       "                                   documentidentifier  \\\n",
       "0   http://www.dailynewsegypt.com/2015/10/11/tgm-m...   \n",
       "5   https://en-maktoob.news.yahoo.com/mideast-stoc...   \n",
       "8   http://www.barossaherald.com.au/story/3429242/...   \n",
       "15  http://www.cachevalleydaily.com/news/national/...   \n",
       "31  http://www.dubaicityguide.com/site/news/news-d...   \n",
       "\n",
       "                                       enhancedthemes  \\\n",
       "0   ECON_WORLDCURRENCIES_DOLLAR,2612;ECON_WORLDCUR...   \n",
       "5   ECON_OILPRICE,114;ECON_STOCKMARKET,52;ECON_STO...   \n",
       "8   TAX_FNCACT_BACKBENCHER,2073;AGRICULTURE,907;AG...   \n",
       "15  TAX_FNCACT_CANDIDATES,163;TAX_FNCACT_CANDIDATE...   \n",
       "31  SOC_EMERGINGTECH,1781;WB_1467_EDUCATION_FOR_AL...   \n",
       "\n",
       "                                    enhancedlocations  \\\n",
       "0   [Milan, Lombardia, Italy, IT, Cairo, Egypt, EG...   \n",
       "5   [Dubayy, AE, Qatar, QA, QA, QA, Qatar, QA, QA,...   \n",
       "8   [Indonesian, ID, ID, ID, Australian, AS, AS, A...   \n",
       "15  [Alexandria, Egypt, EG, Alexandria, Egypt, EG,...   \n",
       "31                                [Dubai, Dubayy, AE]   \n",
       "\n",
       "                                                 tone extrasxml  \\\n",
       "0   [1.76991150442478, 2.54424778761062, 0.7743362...       NaN   \n",
       "5   [0.465116279069767, 0.930232558139535, 0.46511...       NaN   \n",
       "8   [-4.93506493506493, 2.07792207792208, 7.012987...       NaN   \n",
       "15  [0.453857791225415, 5.29500756429652, 4.841149...       NaN   \n",
       "31  [3.93873085339168, 4.37636761487965, 0.4376367...       NaN   \n",
       "\n",
       "    translationinfo  mean_tone  enhanced_ratio  \n",
       "0               NaN   4.793510        0.878049  \n",
       "5               NaN   3.720930        0.000000  \n",
       "8               NaN   5.238095        0.000000  \n",
       "15              NaN   6.707010        0.995745  \n",
       "31              NaN   6.856309        0.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['enhanced_ratio'] = filtered_df.enhancedlocations.apply(lambda x: filtered(x, theme_filter))\n",
    "# Filtering by country\n",
    "#filtered_df = filtered_df[filtered_df[''].apply(lambda x: any(keyword in x for keyword in country_filter)) or filtered_df[''].apply(lambda x: any(keyword in x for keyword in country_filter))]\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c583b04bd300b6c5291ff1176f97d61ae1bc889ec7f2c1c609b2578a37b6e7cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
